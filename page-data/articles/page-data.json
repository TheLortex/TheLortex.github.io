{"componentChunkName":"component---src-pages-articles-tsx","path":"/articles/","result":{"data":{"allFile":{"group":[{"fieldValue":"esp32","nodes":[{"childMdx":{"frontmatter":{"title":"Work in progress status and links","description":"This article holds my Github projects links related to Mirage-OCaml-ESP32 and will be updated with my progress. It also serve as my notepad and thought long-term storage so you might expect random stuff there too!","date":"02/10/2018","tags":null,"inline":null,"slug":"status","hero_image_alt":null,"hero_image":null},"body":"\n* We now have native compilation for ESP32! That opens a lot of possibilities!\n* Mirage is available for ESP32 target, it allows to build complex applications for this platform, such as an HTTPS server.\n* All this work is stored under a Github organization: [well-typed-lightbulbs](https://github.com/well-typed-lightbulbs).\n\n## Native backend\n\n* OCaml 4.06.0 with xtensa target and custom settings to build the bytecode runtime on the ESP32. The best way to have a functional cross-esp32 toolchain is to install the `ocaml-esp32` opam package from opam-cross-esp32. It requires an `4.06.0+32bit` base compiler.\n  - [Github - ocaml-esp32](https://github.com/well-typed-lightbulbs/ocaml-esp32)\n* I have code generation and linking working. This is an example with the files I used to build my native hello world!\n  - [Github - ocaml docker sample](https://github.com/well-typed-lightbulbs/esp32-docker-samples/tree/master/ocaml)\n\n## Cross-compilation of a Mirage unikernel\n\n* See [Build your own Mirage](https://www.lortex.org/posts/mirage/esp32/2018/06/22/build-your-own-mirage.html) article to find out more about building a Mirage unikernel.\n\n## Mirage unikernel samples\n\n* Three sample docker scripts that build for ESP32: [esp32-docker-samples](https://github.com/well-typed-lightbulbs/esp32-docker-samples). They build C, OCaml and Mirage code.\n* Three sample Mirage applications: [mirage-esp32-samples](https://github.com/well-typed-lightbulbs/mirage-esp32-samples). `hello_world`: a basic printer. `ap_dhcp`: an access point delivering IPs trough DHCP. `lcd_wifi_demo`: makes use of network and lcd screen features. "}},{"childMdx":{"frontmatter":{"title":"What now?","description":"My OCaml Labs internship is done, and my ESP32 work has been presented at ICFP 2018's OCaml Workshop. So what's next ?","date":"02/10/2018","tags":null,"inline":null,"slug":"what-now","hero_image_alt":null,"hero_image":null},"body":"\n## OCaml Labs internship overview\n\nMy research on OCaml/ESP32 devices was done as a research project in Cambridge Computer Laboratory's [OCaml Labs](http://ocamllabs.io/). The internship lasted 5 months, from March to July 2018, and I worked under the supervision of [Anil Madhavapeddy](http://anil.recoil.org/). I presented my internship work on September 4, and I got a final mark of 18/20, confirming the validation of my first year of Master's degree in computer science !\n\nAs a recap, I achieved:\n\n- a working OCaml native compilation backend for Xtensa architecture.\n- an opam distribution containing cross-compilation package support for ESP32.\n- decent Mirage integration, including:\n  - operating system features: time, events and collaborative threading.\n  - network features: TCP/IP, DHCP, DNS, HTTP, TLS.\n  - esp32 features: Wifi, LCD screen.\n  - mirage command line interface integration that allows easy builds.\n\nAll the information you might need to actually use this project is available on the [status](https://www.lortex.org/status/2018/10/02/status.html) page.\n\n## ICFP 2018 - OCaml Workshop talk\n\nimport Talk from \"./ESP32_talk.pdf\"\n\nMy talk was accepted for the OCaml Workshop co-located with ICFP 2018 in Saint-Louis, USA. \n- Informations on the talk are available on the ICFP 2018 website: [here](https://icfp18.sigplan.org/event/ocaml-2018-papers-ocaml-on-the-esp32-chip-well-typed-lightbulbs-await).\nA video will be available soon. \n- You can find the slides <a href={Talk}>here</a>. Finally, here are some pictures!\n\nimport Icfp1 from \"../galleries/icfp/icfp1.jpg\";\nimport Icfp2 from \"../galleries/icfp/icfp2.jpg\";\nimport Icfp3 from \"../galleries/icfp/icfp3.jpg\";\nimport Icfp4 from \"../galleries/icfp/icfp4.jpg\";\nimport Icfp5 from \"../galleries/icfp/icfp5.jpg\";\n\n<div\n  style={{\n    display: \"flex\",\n    flexDirection: \"row\",\n    alignItems: \"center\",\n    flexWrap: \"wrap\",\n  }}\n>\n  <img\n    src={Icfp1}\n    style={{\n      flex: 1,\n      display: \"block\",\n      flexBasis: 0,\n      width: \"20%\",\n      height: \"auto\",\n    }}\n  />\n  <img\n    src={Icfp2}\n    style={{\n      flex: 1,\n      display: \"block\",\n      flexBasis: 0,\n      width: \"40%\",\n      height: \"auto\",\n    }}\n  />\n  <img\n    src={Icfp3}\n    style={{\n      flex: 1,\n      display: \"block\",\n      flexBasis: 0,\n      width: \"40%\",\n      height: \"auto\",\n    }}\n  />\n  <img\n    src={Icfp4}\n    style={{\n      flex: 1,\n      display: \"block\",\n      flexBasis: 0,\n      width: \"20%\",\n      height: \"auto\",\n    }}\n  />\n  <img\n    src={Icfp5}\n    style={{\n      flex: 1,\n      display: \"block\",\n      flexBasis: 0,\n      width: \"20%\",\n      height: \"auto\",\n    }}\n  />\n</div>\n\n## What comes next ?\n\nI'll pause my ESP32 work, to focus on other fields and courses for a semester. However this is not the end of the project and there remains a lot to achieve. Things that I want to do include building new libraries to take advantage of ESP32 features and make them available trough Mirage abstractions.\n\nTODO:\n\n- Programming Ultra-Low Power processor\n- Reading sensors\n- Integrating sensors in the event system\n- Bluetooth integration\n- Reducing OCaml memory footprint\n- Benchmarking\n"}},{"childMdx":{"frontmatter":{"title":"Build your own Mirage application!","description":"A month after the first proof of concept, work has been done and here is how you can start to experiment with Mirage on ESP32 chips.","date":"22/06/2018","tags":null,"inline":null,"slug":"build-your-own-mirage","hero_image_alt":null,"hero_image":null},"body":"## Well-typed lightbulb organisation\n\nAll my work can now be found in the [`well-typed-lightbulb`](https://github.com/well-typed-lightbulbs) Github organisation! It consists in:\n* `ocaml-esp32`: OCaml 4.06 compiler with an `xtensa-esp32-elf` configuration option.\n* `opam-cross-esp32`: Opam repository to cross-compile packages to the ESP32 target.\n* `mirage-*-esp32`: Mirage libraries for ESP32.\n* `mirage`: Mirage CLI to configure an ESP32 unikernel.\n* `wifi-esp32`: Wifi bindings at the interface between OCaml and the C driver.\n* `lcd-esp32`: LCD bindings for the SPI LCD display on the ESP32 WROVER kit.\n* And some forks needed for Mirage on ESP32 development.\n\n## How to use these tools\n\nI have ported more than 80 packages to cross-compile on ESP32. They are not available on the official opam repo and you need to use my custom github repo.\nAn OCaml 4.06 32bit compiler is the only prerequisite for ESP32 cross-compilation. Make you are in an appropriate switch (`4.06.0+32bit` for example).\nAfter that, you can setup my custom opam repository.\n```\nopam repo add git https://github.com/well-typed-lightbulbs/opam-cross-esp32.git\n```\nYou'll be able to install the mirage configuration tool fork:\n```\nopam install mirage\n```\n\nAfter that you'll be able to build unikernels with these steps:\n* `mirage config -t esp32` to setup an ESP32 application.\n* `make depends` will automatically install the ESP toolchain, the OCaml cross-compiler for ESP32 architecture and cross-compile Mirage libraries.\n* You can then configure your ESP32 application by using `make menuconfig`. From there you can tweak a lot of settings, but you just have to make sure that the flash size is higher than 2MB and to input the correct serial port (`/dev/ttyUSB0` or `/dev/ttyUSB1` in general).\n* Then `mirage build`\n* And finally `make flash monitor`\n\n## Program your unikernel\n\n### Features\n\n* Wifi access point and station (both can be operating at the same time) that can be accessed trought Mirage's network interface (`netif \"sta\"` or `netif \"ap\"`).\n* LCD screen can be programmed trough `lcd-esp32` library.\n* Wifi events can be used with `wifi-esp32` library.\n\n### Samples \n\n* Some sample unikernels: [`mirage-esp32-samples`](https://github.com/well-typed-lightbulbs/mirage-esp32-samples)\n* Docker scripts of the whole build process: [`esp32-docker-samples`](https://github.com/well-typed-lightbulbs/esp32-docker-samples)\n\n## Remaining work awaits\n\nThere remains a lot of documentation and optimisations to do! I hope to reduce even further the size of Mirage binaries, and especially dynamic memory consumption! For now, only very simple Mirage applications can hold on a 512KB of RAM chip. Hopefully all the unikernels I tested fit on my 4MB of RAM development board.\n"}},{"childMdx":{"frontmatter":{"title":"A Mirage unikernel running on an ESP32","description":"I finally hacked my way into running a first Mirage hello world!","date":"04/05/2018","tags":null,"inline":null,"slug":"success","hero_image_alt":null,"hero_image":null},"body":"import Video from \"./esp32.webm\"\n\n## First, the video!\n\n<video controls loop=\"loop\" width=\"100%\">\n  <source src={Video} type=\"video/webm\" />\n</video>\n\n## What has been achieved\n\nAfter a long way of hacking and debugging my native code emitter in the OCaml compiler, I've finally come to build and run the first example in Mirage unikernels!\nI'm able to build a whole Mirage project and run it on an ESP32 with 4Mb of extended RAM. It's more of a proof of concept, this probably doesn't work out of the box as I hacked a lot of things on the way. I tried to explain what I did in the bottom of this article but maybe I forgot some steps. \n\nThe whole example size is:\n* Flash code: 917942 bytes\n* Flash rodata: 473868 bytes\n* Static data-RAM: 66324 bytes (36.7% used)\n* Static instruction-RAM: 43661 bytes (33.3% used)\n\nI'll be working on getting runtime informations in order to see how hard it would be to run Mirage unikernels on ESP32 without additional RAM. Right now it goes out of memory in the startup code, as it tries to allocate 128kb of frame table (whereas 178kb of dynamic memory is available in total). \n\n### opam-cross-esp32\n\nEvery mirage package needed to build a hello world example has been ported in this `opam-cross-esp32` OPAM repository. It's [available](https://github.com/TheLortex/opam-cross-esp32) on Github.\nThere are some other packages for ESP32 development:\n\n* esp32-toolchain-gcc: xtensa-esp32-elf- prefixed binutils set up in path, located in (xtensa-esp32-elf) subdirectory in the switch. \n* ocaml-esp32: the cross-compiler, needed to build almost every other package. It's installed in a subdirectory (esp32-sysroot) in the switch.\n* esp32-idf-headers: updates the compiler include path to contain the ESP32 IDF headers. \n* mirage-esp32: mirage runtime implementation for esp32. \n* ctypes-esp32: ctypes implementation for esp32, using libffi. But it's useless as dynamic linking is not supported.. I will use cstubs generation in the future.\n\n### ocaml-esp32\n\nThe compiler has now a full native backend to esp32 targets. It's indeed subject to a lot of optimizations as it's a first running draft. \n[Available here](https://github.com/TheLortex/ocaml-esp32)\n\n### mirage-esp32\n\nStubs and OS interface for esp32 platform.\n[Available here](https://github.com/TheLortex/mirage-esp32)\n\n### mirage\n\nAdds an esp32 target in mirage configuration tool. It's not working as intended though.\n[Available here](https://github.com/TheLortex/mirage)\n\n### hello_mirage\n\nThe first mirage sample to fully run on ESP32.\n[Available here](https://github.com/TheLortex/hello_mirage)\n\n## There remains hacks to do, and it's not intended to work out-of-the-box right now.\n\n* Update `bigarray` META to remove `unix` dependency.\n* Update `mirage-profile` META to remove `ppx_tools_versioned` dependency.\n* `num-esp32` needs to be built twice\n* `mirage config -t esp32` needs to be worked on, and should generate the correct jbuild file.\n* `esp32-idf-headers` doesn't install every headers in the root as intended. A `mv include/* .` and `mv includes/* .` in `<switch>/xtensa-esp32-elf/xtensa-esp32-elf/include` is needed to finish the installation.\n"}},{"childMdx":{"frontmatter":{"title":"Compiling and linking for ESP32","description":"A guide to a full native compilation workflow for ESP32","date":"27/04/2018","tags":null,"inline":null,"slug":"compiling-and-linking-for-esp32","hero_image_alt":null,"hero_image":null},"body":"I've got native OCaml code running! It seems to pass all the runtime tests, and as I fixed some GC segfaults I'm now pretty confident in the backend code. \nIt's not optimized at all, but you can now experiment with OCaml on ESP32 MCUs. \n\n## OCaml cross-compiler installation\n\nSwitch opam to OCaml version 4.06 or a 4.07 as only these two versions are supported, using the `opam switch` command.\n\nAdd my cross-compilation repository in opam, with:\n```\nopam repo add cross-esp32 https://github.com/TheLortex/opam-cross-esp32.git\n```\nAfter that, you'll be able to install the cross-compiler, with:\n```\nopam install ocaml-esp32\n```\n\nYou now have an OCaml cross-compiler for esp32 installed in `~/.opam/<switch>/esp32-sysroot/`. \n\n## Cross-compiling OCaml libraries\n\nYour favorite build system can already cross-compile code. You can either use\n* `jbuilder build -x esp32 ...`\n* `ocamlfind -toolchain esp32 ...`\n* `env OCAMLFIND_TOOLCHAIN=esp32 ocamlbuild ...`\nto build libraries.\n\nThe libraries used by these build systems are located in `~/.opam/<switch>/esp32-sysroot/lib/`. A good thing to know is that jbuilder automatically makes the difference between host code and target code, hence enabling the use of ppx tools. \n\n## Building an ESP32 application\n\nTo build an esp32 application, you'll need to link native code with the ESP-Iot Development Framework which contains libraries, bootloader code and linker scripts. \n\n[Hello caml](https://github.com/TheLortex/hello_caml) is an example of project structure using jbuilder that builds a flashable binary for esp32. \n\nBasically, it's not complicated:\n* Build and ship OCaml code into a single object:\n  - using the `-output-complete-obj` option on the native compiler `ocamlopt`.\n  - using `jbuilder build -x esp32 _build/default.esp32/main.exe.o` that will automatically use the option.\n* This object file's entry point is `caml_main`. So the next thing to do is create a `startup-c.c` file that defines a function `app_main` which calls `caml_main`. \n* Then everything needs to be linked together, and the ESP32 framework takes the lead to create the final binary. \n"}},{"childMdx":{"frontmatter":{"title":"The Xtensa architecture","description":"Let's have an insight on what kind of processor ESP32 boards rely on. A lot of standard stuff but my attention will be drawn on something called \"windowed registers\"","date":"28/03/2018","tags":null,"inline":null,"slug":"the-xtensa-architecture","hero_image_alt":null,"hero_image":null},"body":"## An architecture to rule them all\n\nXtensa processors instruction sets have an unified specification which can be found [here](https://0x04.net/~mwk/doc/xtensa.pdf). The goal of Tensilica is to provide a modular architecture for RISC processors which allows the designer to have a general processor with specialized instructions as options for a target application. These options can be pre-designed options such as an MMU, floating-point hardware, cache, but the designer can choose to create its own instruction with the Tensilica Instruction Extension language. Tensilica provides an Xtensa Processor Generator that outputs the processor design (in Verilog or VHDL) given an architecture choice for the processor. \n\nThe architecture of every Xtensa processor is described in a single 662 pages long file. It is indeed a relief, coming from ARM never ending manuals for each processor implementation. I'll focus on the Xtensa LX6 that is shipped with ESP32 boards. \n\n## Xtensa LX6 \n\nI found the full processor configuration in an ESP-IDF newlib include file: [newlib/include/xtensa/config/core-isa.h](https://github.com/espressif/esp-idf/blob/master/components/newlib/include/xtensa/config/core-isa.h)\n\n### Architecture\n\n* 32-bits\n* Little-endian\n* 24/16-bit instructions\n* 64 general purpose registers with 16 visible registers\n* Dual-core\n* 240 MHz maximum frequency\n\n### Options \n\n* Code density\n* Zero cost loop\n* 16/32-bit integer multiply\n* Single precision floating-point coprocessor -- very sad as OCaml uses 64-bit floating-point\n* MAC16 (multiply-accumulate functions)\n* Boolean registers\n* Exceptions\n* Interrupts (timer and high-priority interrupts)\n* Memory region protection\n* Debug/JTAG\n\n## Purpose of registers\n\n* a0 is the return address\n* a1 is the stack pointer\n\n## Windowed registers\n\n### Idea\n\nThat's probably one of the most special feature of the LX6, so that's what I'll talk about. The processor contains 64 32-bit registers but only an interval of 16 registers can be seen at each instant. A 4-bit WindowBase special register chooses which range of registers is visible and addressable. This register can be modified by WSR (Write to Special Register) but other instructions have special mechanisms with this feature. \n\n### CALL/ENTRY/RETW \n\n* CALLN `<label>`, CALLXN `<register>`:\n  - CALL4: call a procedure that will move the window by 4 registers.\n  - CALL8: same of 8 registers.\n  - CALL12: you know it. \n  This does not actually move the window but rather takes the 30 first bits of the register, put them in the return address register and use the two last bits to encode the window rotation offset (4, 8 or 12).\n* ENTRY sp, `<frame_size>`\n  This instruction performs the window rotation according to the two highest bits of the return address and update the stack pointer given `<frame_size>`.\n* RETW\n  Rotates back the register window and jump to return address. Note that because the two highest bits are used to encode the window rotation, RETW uses its own two highest bits. Therefore the return address must be in the same 1G as the RETW instruction. I guess that will not be a problem for embedded devices. \n\n### Windowed ABI \n\nWhat happens when we're out of registers. Well the window loops over the first registers and thanks to an exception mechanism the registers are spilled under the original caller stack pointer. When the window will rotate back to this call, it the registers will be unspilled by an exception handler called by RETW. To know if a registere is used or not, another special register WindowStart has 16 bits to describe if each region of registers is used or not. \nThis is described in the Xtensa ISA and I know it's confusing so I'll probably make another article on this matter. "}},{"childMdx":{"frontmatter":{"title":"Last week report","description":"Assembly, code generation and debugging fun!","date":"27/03/2018","tags":null,"inline":null,"slug":"last-week-tonight","hero_image_alt":null,"hero_image":null},"body":"\n\nBack to Cambridge, I decided to focus on assembly code generation, which is the last layer of compilation. \nThere are multiple things to perform to create a new target backend. \n\n## TODO\n\n### In `/asmcomp/`:\n\nThis directory contains for each architecture a sub-directory that implements architecture-specific code. I created my own `xtensa` sub-directory, which contains the following files:\n\n* `emit.mlp`: a pre-processed OCaml file (on which syntax highlighting has a lot of troubles by the way). It implements `asmcomp/emit.mli` and consists in translating a `Linearize.fundecl` code to assembly. This is obviously architecture-specific and I worked on it by roughly translating what was done on ARM. \n* `arch.ml`: defines architecture-dependant values such as endianness, addressing modes. \n* `proc.ml`: describes registers, calling conventions and the side effects of instructions on registers. Used by the register allocator. \n* `selection.ml`: operation and addressing selection overriding default behavior. Useful as Xtensa doesn't have double precision hardware floating point for example. \n* `scheduling.ml`: instruction timing hints.\n* `CSE.ml`: common subexpression elimination. Set to default.\n* `reload.ml`: instruction reloading. Set to default.\n\n### In `/asmrun/`:\n\n* `xtensa.S`: an architecture-specific, handwritten assembly code is here to make the glue between C and OCaml code. It handles calls to the garbage collector. \n\n\n## Progress \n\n### Writing code\n\nLast week I finished to fill `emit.mlp` and `proc.ml` to start debugging. I figured out when linking failed that I forgot to fill `xtensa.S` assembly stubs. \nThere are a bit of features to fill in:\n\n* `caml_call_gc`: call the runtime garbage collector. \n* `caml_alloc1`: allocate 4 bytes\n* `caml_alloc2`: allocate 8 bytes\n* `caml_allocN`: allocate N-4 bytes, with N given in a register\n* `caml_c_call`: call a C function \n* `caml_start_program`: entry point after caml runtime startup\n* `caml_callback_exn`: callback from C to OCaml with one argument\n* `caml_callback2_exn`: callback from C to OCaml with two arguments\n* `caml_callback3_exn`: callback from C to OCaml with three arguments\n* `trap_handler`: callback from exception\n* `caml_raise_exn`: raise an exception from OCaml\n* `caml_raise_exception`: raise an exception from C\n\n### Linking it\n\nThe process is not that straightforward as compiling and linking for ESP32 relies on the espressif's Iot Development Framework with contains the linker script and required libraries. The ~easiest~ way I found, *yet*, to have some OCaml native code running on the ESP32 is the following:\n\n* `ocamlopt-esp32 test.ml -dstartup -o main.o -S -dstartup` will generate two assembly files and fail on linking:\n- `main.s` is the main source code\n- `main.o.startup.s` is the startup code which will then call `main.s` entry point. \n* Create `startup-c.c` that will be the glue between ESP-IDF entry point `app_main` and OCaml runtime entry point `caml_main`.\n* Put all these files in an ESP-IDF component subdirectory of a [project](https://github.com/espressif/esp-idf/tree/2935e95/examples/get-started/hello_world). That is for example `hello_caml/main/`. \n* Put library files generated by the compilation of ocaml-esp32 in a lib directory `hello_caml/lib/`:\n- `libasmrun.a`\n- `libstdlib.a`\n- `std_exit.o` \n* Create a relocatable object file `startup-c.o` from `startup-c.c`, `main.s` and `main.o.startup.s`. \n* Add the libraries in the component Makefile through `COMPONENT_ADD_LDFLAGS` and `COMPONENT_EXTRA_INCLUDES`.\n* `make`\n\n### Debugging stuff\n\n* I use QEMU for debugging. This [github](https://github.com/Ebiroll/qemu_esp32) explains how to do it. It works out of the box with the gdb shipped with the repository. \n* ESP32 WROVER kits have a JTAG interface, that will allow me to test my code on real hardware, once it works on QEMU. \n\n## Funny stuff encountered\n\n### Conditional branches don't have legs\n\nThe conditional branch has a range of +-128 bytes. My generated code tried to jump further, generating the `Error: jump target out of range; no usable trampoline found`. I had to put a jump instruction close the conditional as I often need to go far away. The jump to label has a range of +-131075 bytes. If that's not enough I can address the whole space with a jump to address in register. \n\n### Never look forward\n\nThe PC-relative load has a range of [-262141, -4]. Therefore data must be before every load and store instructions. The assembler handles this alone when compiling a single file. But the linker doesn't seem to handle that well accross files. I had to put additional symbols.\n\n### What you see is not what you get\n\nXtensa processors can have a feature called \"Windowed registers\". It allows a processor to have a given number of registers (64) but only a subset interval of these registers are visible at each instant (16). \n\nOn call, you can ask the processor to move this window to the right, by a number of registers. It can be 0, 4, 8, or 12. There are special instructions that magically handles the fact that this window can overflow by spilling registers in stack memory. \nThat makes the ABI a bit special as `a8` register of the caller is the `a0` register of the callee if the `call8` instruction is used. \n\nUsing `call4`, `call8` and `call12` is compatible as the `entry` function handles everything for you. However `call0` is not compatible with `entry` as the document explains it throws an IllegalInstruction exception. Guess what? I wanted to start with `call0` ABI as it's simpler to reason about, but C code is compiled against `call8` ABI. \n\n"}},{"childMdx":{"frontmatter":{"title":"Mirage on embedded devices: where are we?","description":"As an intern at the OCamlLab, my project is to port MirageOS on ESP32 boards. This is my first post to explain a bit what is the subject, give some links, hints on what is to be done.","date":"20/03/2018","tags":null,"inline":null,"slug":"mirage-and-esp32","hero_image_alt":null,"hero_image":null},"body":"## A bit of a recap \n\nAs an intern at the [OCamlLab](https://ocamllabs.io/), my project is to port [MirageOS](https://mirage.io/) on a [ESP32 boards](https://www.espressif.com/en/products/hardware/esp32/overview). \n\nThis will be done by two main projects:\n\n* Set up a cross-compilation toolchain from Mirage libraries to ESP32 target. It will be mainly for bytecode generation along with C stubs built with the xtensa gcc toolchain. \n\n* Add a new target to the OCaml compiler to have native code generation for xtensa processors.\n\n### What is ESP32 \n\nESP32 is a series of chip microcontrollers which embeds Wifi and Bluetooth controllers. It integrates the following hardware:\n* Dual core Xtensa LX6 processors - 240Mhz\n* Ultra-low power coprocessor\n* 520kb of RAM\n* 4Mb of read-only flash\n* Wifi b/g/n transceiver\n* Bluetooth 4.2 Low Energy\n* Multiple peripheral interfaces\n* 5μA deep-sleep current\n\nThe base price of such a chip is $5, which makes it fairly cheap. Here are some derivations of the ESP32:\n* [Base chip + USB](https://wiki.wemos.cc/products:lolin32:lolin32_lite) ($5)\n* [Base chip + USB + Battery powered](https://www.sparkfun.com/products/13907) ($20)\n* [Base chip + 4Mb PSRAM](http://www.electrodragon.com/product/esp32-wrover-v4-module-based-esp32/) ($4.40) \n* [Base chip + USB  + 4Mb PSRAM + LCD screen + JTAG over USB + SD card support](http://www.electrodragon.com/product/esp32-wrover-kit/) ($37.10)\n\nHence this chip is very interesting for IoT projects, as it is versatile, low-power, and connected. \n\n#### Programming on ESP32\n\nEspressif published a development guide and toolchain for C programming. You can find it as the [ESP-IDF](http://esp-idf.readthedocs.io/en/latest/) (IoT Development Framework) and there are all the resources needed to develop on this board. It contains a lot of documented libraries that help exploiting the features of ESP32 chips. It's fairly easy to compile a simple program as the framework will automatically compile and link the code with ESP libraries and newlib, creating a flashable binary. \n\nThis chip can also programmed trough:\n* [MicroPython](http://micropython.org/download#esp32) (Python for microcontrollers) features a Python toplevel on serial over USB. MicroPython libraries includes for example an easy way to connect to a Wifi hotspot and communicate with the world. \n* [Arduino](https://github.com/espressif/arduino-esp32)\n\n### What is Mirage ? \n\n\"MirageOS is a library operating system that constructs unikernels for secure, high-performance network applications across a variety of cloud computing and mobile platforms\". Written in OCaml, Mirage relies on opam package manager to download and build libraries. \n\n* The `mirage` package contains the OCaml tool which will build an unikernel from sources to a specific target. `mirage configure -t xen` would for example create the list of packages needed to compile an unikernel for a Xen hypervisor. \n\n* The mirage library is composed of a lot of features libraries, sometimes target-specific, whose types implement one of the `mirage-types`. These types defines interfaces for:\n  - Block devices\n  - Channels\n  - Time \n  - Console \n  - Filesystem\n  - Network\n  - ...\n\n### Why Mirage should be ported to the ESP32 \n\nMirage is a library that allows the user to build applications without relying on a particular operating system, compiling it with minimal amount of libraries needed to run the application on bare metal or on top of an hypervisor. Thus a MirageOS unikernel can rely on operating system features such as network or devices without shipping millions of useless lines of code a typical OS can have. \n\nThis improves security, performances and reduces the memory footprint of an application. That's why having Mirage unikernels running on ESP32 boards is a great goal. \n\n## Where are we now ?\n\nWe want to be able to ship OCaml code on ESP32 boards. However, Xtensa processors use a [specific](https://0x04.net/~mwk/doc/xtensa.pdf) instruction set. This instruction set is currently not supported by the OCaml compiler, the only compiler toolchain building for ESP32 being the [xtensa-esp32-elf](https://dl.espressif.com/dl/xtensa-esp32-elf-linux64-1.22.0-61-gab8375a-5.2.0.tar.gz) toolchain whose code hasn't been distributed. \n\n### Bytecode execution on the ESP32\n\nHopefully, OCaml runtimes are written in C and can be built with the cross toolchain. With some efforts tweaking constants and Newlib compilation settings, Sadiq successfully compiled an OCaml code into bytecode which could be executed on an ESP32 board: [Getting OCaml running on the ESP32](https://toao.com/blog/getting-ocaml-running-on-the-esp32). This is promising as it means we could build, link and run any OCaml library on an ESP32 target.\n\nHowever two problems were encountered:\n* OCaml's `Printf.printf` doesn't work out of the box. I figured out that ESP-IDF's VFS is a bit broken and doesn't correctly implement file descriptors behavior. I'll write on article on that matter. \n\n* Using several libraries such as `Map` and `Pervasives`, the size of the generated bytecode becomes too big for the 520kb RAM to hold. No problem! Let's put it in flash, I just have to change a `static` to a `static const` in the C file containing the bytecode. Well it doesn't work out of the box as the bytecode runtime actually perform an update pass over the bytecode to prepare it for threaded mode, therefore if the bytecode is set in flash memory it can't be updated and an exception is raised. That pass had to be disabled in order to fix the issue. After that I could build more complex programs, generate their bytecode and run it on an ESP32 board. \n\n### Cross-compilation of mirage libraries\n\n#### Mirage ESP32 target\n\nThe first step towards compiling an unikernel with Mirage is to add a new target on the mirage configuration tool. Adding an esp32 target allows `mirage configure -t esp32` to generate an unikernel package which will depend on ESP32 libraries implementations. \n\n#### opam-cross-esp32 libraries\n\nMirage libraries required to build an unikernel come in a great number. Opam handles everything in case of host compilation, but there isn't yet any way to cross-compile a package with its dependencies out of the box. \n\nAs I looked online I figured out the best way to cross-compile stuff on OCaml is to do as `whitequark` did with `opam-cross-android`. The idea is to create for every package `<*name*>`, a clone package `<*name-esp32*>` which is cross-compiled with an `ocaml-esp32` cross-toolchain and installed within a specific prefix. \n\nThis is tedious work, and it can hardly be automated as there are a lot of patterns and use of different build systems. Generation of bytecode libraries along with C libraries is not such a problem, but it's a bit ugly as some of these libraries rely on preprocessing libraries and tools that need to be built with a host toolchain. \nFor example a build that rely on an ocamlbuild plugin need to have the plugin built with the host toolchain, before switching to the target toolchain in order to build the library. \n\nRight now every dependency of the noop mirage sample has its `-esp32` version in [opam-cross-esp32](https://www.github.com/TheLortex/opam-cross-esp32). However it has been done in a funky/hacky way and it doesn't build out of the box. \n\n### Native xtensa backend for the OCaml compiler\n\nTo reduce memory footprint and speed up execution, the end goal is to have a native backend of the OCaml compiler for ESP32 targets. This implies digging in the compiler source code as the documentation is fairly.. [empty](https://github.com/ocamllabs/ocaml-internals/wiki). The work consists in writing the last layer of compilation which generates assembly code from the last intermediary language of OCaml compilation. It's not that hard as I can read the source of several other backends for common architectures (ARM, i386, ..) and translate from there using the Xtensa Instruction Set Architecture."}}]},{"fieldValue":"misc","nodes":[{"childMdx":{"frontmatter":{"title":"Implementing value speculation in OCaml","description":"Value speculation exploits the CPU branch predictor to improve instruction parallelism. Here is an example of it in OCaml.","date":"05/05/2023","tags":null,"inline":null,"slug":"value-speculation-ocaml","hero_image_alt":"This is convoluted","hero_image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#9898a8","images":{"fallback":{"src":"/static/8acd8434e4a2fc442e65896b7b7c1894/ae980/seum_hero.png","srcSet":"/static/8acd8434e4a2fc442e65896b7b7c1894/b216d/seum_hero.png 161w,\n/static/8acd8434e4a2fc442e65896b7b7c1894/6ef0d/seum_hero.png 321w,\n/static/8acd8434e4a2fc442e65896b7b7c1894/ae980/seum_hero.png 642w","sizes":"(min-width: 642px) 642px, 100vw"},"sources":[{"srcSet":"/static/8acd8434e4a2fc442e65896b7b7c1894/d272d/seum_hero.webp 161w,\n/static/8acd8434e4a2fc442e65896b7b7c1894/e567c/seum_hero.webp 321w,\n/static/8acd8434e4a2fc442e65896b7b7c1894/81d96/seum_hero.webp 642w","type":"image/webp","sizes":"(min-width: 642px) 642px, 100vw"}]},"width":642,"height":475.99999999999994}}}},"body":"\nCPUs are very good at doing things in parallel, even in a single core context.\nIndeed, speculative execution of code and instruction reordering helps the CPU\nensure that the pipeline is always full. However, data dependencies in the\nsequence of instructions might cause the CPU to have to wait for data, be it\nfrom the L1 cache or the much slower RAM storage. Francesco Mazzoli shows in their blog post, [Beating the L1 cache with value speculation](https://mazzo.li/posts/value-speculation.html) ,\nthat optimizing the critical path will in some conditions yield huge performance\nimprovements.\n\nThis article demonstrates that this optimisation can be implemented in the\nOCaml programming language. Knowing how OCaml values are represented in memory is useful, here is a chapter of Real World OCaml on that matter: [Memory Representation of Values](https://dev.realworldocaml.org/runtime-memory-layout.html).\n\n## Fast list iterations using one simple trick™\n\nLet's start by instantiating a linked list of 10000 random numbers.\n\n```ocaml\nlet l = List.init 10000 (fun _ -> Random.int 1024)\n```\n\nNow, let's sum the numbers 100k times and see how long that takes. To obtain these statistics, `perf stat` was used with the default settings on programs compiled with OCaml 5.0.\n\n```ocaml\nlet rec sum (accumulator: int) (cell: int list) =\n  match cell with\n  | head::tail -> sum (accumulator + head) tail\n  | [] -> accumulator\n\nfor _ = 1 to 100000 do\n  ignore (sum 0 l)\ndone\n```\n\n```\n Performance counter stats for './a.out sum':\n\n          1 368,91 msec task-clock:u                     #    0,999 CPUs utilized\n     4 835 597 233      cycles:u                         #    3,532 GHz\n     9 005 641 989      instructions:u                   #    1,86  insn per cycle\n     3 001 229 709      branches:u                       #    2,192 G/sec\n           195 819      branch-misses:u                  #    0,01% of all branches\n```\n\nConveniently, we're doing one billion additions (10000 list items, repeated 100k times). So each iteration is taking:\n\n- 1.36 nanoseconds\n- 4.8 cycles\n- 9 instructions\n- 3 branches\n\nWe can already see that the CPU is cramming multiple instructions per cycle.\nUsing the [compiler explorer](https://godbolt.org/), the following assembly is obtained:\n\n```nasm\ncamlExample__sum_268:\n        subq    $8, %rsp\n.L101:\n        cmpq    (%r14), %r15         # check if GC is waiting for us\n        jbe     .L102                # branch #1\n.L103:\n        testb   $1, %bl              # check if at end of list\n        je      .L100                # branch #2\n        addq    $8, %rsp\n        ret\n.L100:\n        movq    8(%rbx), %rdi        # load tail element of list\n        movq    (%rbx), %rbx         # load head element of list\n        leaq    -1(%rbx,%rax), %rax  # add it to accumulator\n        movq    %rdi, %rbx           # move tail element for next iteration\n        jmp     .L101\n.L102:\n        call    caml_call_gc@PLT\n.L104:\n        jmp     .L103\n```\n\nI've tried to think like a CPU in order to explain the numbers according to the perf results, but as so many pieces are involved I assumed it would be hard for everything to be correct. Instead, we'll try to get a good _intuition_ by thinking in terms of _data dependency_. Basically, the assumption is that things that do not depend on each other can be ran in parallel. The second assumption is that thanks to the _branch predictor_, branch instructions are supposed to have zero cost and they don't introduce data dependencies. Instead, the CPU predicts whether the program will go through the branch and continue execution. In case of misprediction, the CPU will roll back computations for us.\n\nSo here is the data dependency chart for this program, showing how two iterations are expected to be ran, with the critical path in red:\n\n![data chart](./sum_chart.png)\n\nEven if the tail pointer is loaded from cache, we still have to pay a 4 cycles cost to fetch from the L1 cache.\n\nThe **Check GC** part of the loop is independent from the rest, and is useful in a multicore context as every domain of the program has to synchronize when performing garbage collection.\n\n## Value speculation\n\nIt's time to open the rune book and perform some dark magic. We know that we\nwon't get past that 4 cycles per iteration bottleneck unless there is a way to\nbypass the pointer chasing. To do that, we're going to do what was done in\nthe value speculation article, but in pure OCaml.\n\nimport ObjMagic from \"./obj_magic.jpg\";\n\nThe principle is the same: `cell` is converted to a \"pointer\" using the forbidden <a href={ObjMagic}>`Obj.magic`</a> function. Using the value of the `previous` list\ncell pointer, we can compute `delta`, the number of bytes between the two last cells.\nThis is used to estimate where will be the next cell. If the prediction is correct,\nthe memory load of the next cell address is effectively bypassed, and the CPU can\ndirectly start working on the next iteration. If not, the branch predictor rolls back the\ncomputation.{\" \"}\n\n```ocaml\nlet current : int = Obj.magic cell in                   (* convert list cell to pointer (integer value) *)\nlet delta : int = current - previous                    (* compute delta with previous pointer *)\nlet prediction : int list = Obj.magic (current + delta) (* use delta to predict next pointer*) \n```\n\n![illustration of the delta computing mechanism ](./seum_delta_1.png)\n\nHere is the full program. Note that the delta calculation was inlined for performance reasons. \n\n(`current + delta = current + (current - previous) = 2 * current - previous`)\n\n```ocaml\nlet rec seum (previous : int) (accu : int) (cell : int list) =\n  match cell with\n  | [] -> accu\n  | head::tail ->\n    let current : int = Obj.magic cell in\n    let prediction : int list = (* compute prediction *)\n      Obj.magic (2 * current - previous)\n    in\n    seum\n      current\n      (accu + head)\n      (if prediction == tail then prediction else tail) (* validate prediction *)\n```\n\nThe program is executed with the same input and...\n\n```\n Performance counter stats for './a.out seum':\n\n            944,67 msec task-clock:u                     #    1,000 CPUs utilized\n     3 422 107 884      cycles:u                         #    3,623 GHz\n    16 006 647 403      instructions:u                   #    4,68  insn per cycle\n     5 001 230 197      branches:u                       #    5,294 G/sec\n           225 781      branch-misses:u                  #    0,00% of all branches\n```\n\nPer iteration:\n\n- 0.94 nanoseconds\n- 3.4 cycles\n- 16 instructions\n- 5 branches\n\nWe got past the bottleneck ! What we're effectively doing is transforming the list iteration into an array iteration. And this works, because there are situations where OCaml lists are allocated in a linear fashion, making the cell addresses predictible. Note in particular the huge number of instructions per cycle.\n\nIf you are not convinced, here is an updated dependency diagram for this program.\n\n![](./seum_chart.png)\n\nBy moving the tail pointer load outside of the critical path, the CPU is able to do more things at once. The following chart shows how one can expect the CPU to execute instructions for three iterations in parallel.\n\n![](./seum_chart_tiled.png)\n\n### The crux of the hack\n\nThe astute reader will wonder how is it possible to use `Obj.magic` to transmute the `int list` to an `int`. Indeed these OCaml types have different representations. \n- An `int list` is a pointer to an OCaml block allocated on the heap. Due to alignment, it always end with a zero bit.\n- An `int` is a primitive OCaml value, the value `n` being represented as the _tagged integer_ `2 * n + 1`.\n\nThis means that usual operations on `int` values won't work on raw pointers.\nFor example, the addition is implemented as `Int.add a b = a + b - 1`. The consequence is that adding two raw numbers together using the OCaml addition will subtract one from the result to account for the expected tags. \n\nFor subtraction, it is similar: `Int.sub a b = a - b + 1`. \n\nThe magic happens when we're combining an addition and a subtraction, so that the whole operation is correct on both pointers and integers:\n```ocaml\nInt.add current (Int.sub current previous) \n  = current + (current - previous + 1) - 1\n  = current + (current - previous)\n```\n\n<details>\n<summary>Here is the full annotated assembly for the curious</summary>\n```nasm\ncamlExample__seum_268:\n        subq    $8, %rsp\n.L103:\n        movq    %rax, %rsi\n        movq    %rdi, %rax\n        cmpq    (%r14), %r15           # check if GC is waiting for us\n        jbe     .L104                  # branch #1\n.L105:\n        testb   $1, %al                # check if at end of list\n        je      .L102                  # branch #2\n        movq    %rbx, %rax\n        addq    $8, %rsp\n        ret\n.L102:\n        movq    8(%rax), %rdx          # load tail element of list cell \n        movq    %rax, %rdi             # move cell pointer to %rdi\n        salq    $1, %rdi               # multiply pointer by two\n        subq    %rsi, %rdi             # subtract previous cell pointer to obtain the prediction\n        cmpq    %rdx, %rdi             # compare tail element with prediction\n        jne     .L101\n        jmp     .L100\n.L101:\n        movq    %rdx, %rdi             # prediction is incorrect, move the tail element in %rdi\n.L100:\n        movq    (%rax), %rsi           # load head element of list cell\n        leaq    -1(%rbx,%rsi), %rbx    # add to accumulator\n        jmp     .L103                  # loop\n.L104:\n        call    caml_call_gc@PLT\n.L106:\n        jmp     .L105\n```\n</details>\n\n### Optimized\n\nI was not satisfied by this mere 45% improvement. What if the loop was unrolled, so that the CPU has more freedom to move instructions around ?\n\n```ocaml\nlet rec seum_unroll (previous : int) (accu : int) (cell : int list) =\n  match cell with\n  | [] -> accu\n  | [a] ->  accu + a\n  | [a; b] -> accu + a + b\n  | [a; b; c] -> accu + a + b + c\n  | a::b::c::d::tail ->\n      let current = Obj.magic cell in\n      let prediction : int list =\n        Obj.magic (2 * current - previous)\n      in\n      seum_unroll\n        current\n        (accu + a + b + c + d)\n        (if prediction == tail then prediction else tail)\n```\n\nThe idea is to iterate on the list by chunks of 4 items. There is still the same amount of work to do, but the value prediction trick is performed once every 4 element.\n\n```\n Performance counter stats for './a.out seum_unroll':\n\n            715,58 msec task-clock:u                     #    0,999 CPUs utilized\n     2 410 830 333      cycles:u                         #    3,369 GHz\n     7 756 543 257      instructions:u                   #    3,22  insn per cycle\n     2 001 229 820      branches:u                       #    2,797 G/sec\n           112 956      branch-misses:u                  #    0,01% of all branches\n```\n\nPer iteration:\n\n- 0.72 nanoseconds\n- 2.4 cycles\n- 7.7 instructions\n- 2 branches\n\n<h1 style={{ fontSize: \"4em\", marginTop: \"-50px\", marginBottom: \"-50px\" }}>\n  <b>91.3%</b> faster. Nice.\n</h1>\n\nAccording the original article, we're now faster than the naive C implementation, but 2x slower than the hand-optimized one. This is all very synthetic but I found it quite interesting that OCaml is able to benefit from the same hacks as C. Of course this won't be useful in a lot of situations, but maybe one will gain some insights on how modern CPU are able to make programs go fast.\n\n---\n\nIf you like this article I'd be glad to have your feedback. \nPublic discussion on [Twitter](https://twitter.com/TheLortex/status/1654563811569836032)\n"}}]}]}},"pageContext":{}},"staticQueryHashes":["2744905544"],"slicesMap":{}}